{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import spacy\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.colors as mcolors\n",
    "import time\n",
    "import scipy.sparse\n",
    "from gensim import matutils,models\n",
    "from gensim import corpora\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "import time\n",
    "import numpy as np\n",
    "import multiprocess as mp\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section-two\"></a>\n",
    "# Preprocessing and cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "**Description of columns in the file:**\n",
    "* product_name - name of book + author\n",
    "* title - title of book review\n",
    "* body - text of the review\n",
    "* rating - rating of the book review\n",
    "* verified_purchase - did the reviewer buy the book or not?\n",
    "* review_date - the date of the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_reviews = pd.read_csv('../data/scraped_amz_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 384233 entries, 0 to 384232\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count   Dtype \n",
      "---  ------             --------------   ----- \n",
      " 0   product_name       384233 non-null  object\n",
      " 1   title              384213 non-null  object\n",
      " 2   body               384126 non-null  object\n",
      " 3   rating             384233 non-null  object\n",
      " 4   verified_purchase  384233 non-null  bool  \n",
      " 5   review_date        384233 non-null  object\n",
      "dtypes: bool(1), object(5)\n",
      "memory usage: 15.0+ MB\n"
     ]
    }
   ],
   "source": [
    "raw_reviews.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>rating</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ace Spades Faridah Abike Iyimide</td>\n",
       "      <td>An Engrossing Page Turner About Race, Class an...</td>\n",
       "      <td>Granted, I've never been a fan of Gossip Girl ...</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>True</td>\n",
       "      <td>June 6, 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ace Spades Faridah Abike Iyimide</td>\n",
       "      <td>An Interesting Debut</td>\n",
       "      <td>“Hello, Niveus High. It’s me. Who am I? That’s...</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>True</td>\n",
       "      <td>June 14, 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ace Spades Faridah Abike Iyimide</td>\n",
       "      <td>Wow</td>\n",
       "      <td>I ordered this book for my teenage daughter an...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>True</td>\n",
       "      <td>September 12, 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ace Spades Faridah Abike Iyimide</td>\n",
       "      <td>Definitely a YA novel</td>\n",
       "      <td>Great plot, childish characterizations (althou...</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>True</td>\n",
       "      <td>August 10, 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ace Spades Faridah Abike Iyimide</td>\n",
       "      <td>A most timely book.</td>\n",
       "      <td>This a very engrossing story.  I was intrigued...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>True</td>\n",
       "      <td>July 5, 2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       product_name  \\\n",
       "0  Ace Spades Faridah Abike Iyimide   \n",
       "1  Ace Spades Faridah Abike Iyimide   \n",
       "2  Ace Spades Faridah Abike Iyimide   \n",
       "3  Ace Spades Faridah Abike Iyimide   \n",
       "4  Ace Spades Faridah Abike Iyimide   \n",
       "\n",
       "                                               title  \\\n",
       "0  An Engrossing Page Turner About Race, Class an...   \n",
       "1                               An Interesting Debut   \n",
       "2                                                Wow   \n",
       "3                              Definitely a YA novel   \n",
       "4                                A most timely book.   \n",
       "\n",
       "                                                body              rating  \\\n",
       "0  Granted, I've never been a fan of Gossip Girl ...  4.0 out of 5 stars   \n",
       "1  “Hello, Niveus High. It’s me. Who am I? That’s...  4.0 out of 5 stars   \n",
       "2  I ordered this book for my teenage daughter an...  5.0 out of 5 stars   \n",
       "3  Great plot, childish characterizations (althou...  4.0 out of 5 stars   \n",
       "4  This a very engrossing story.  I was intrigued...  5.0 out of 5 stars   \n",
       "\n",
       "   verified_purchase         review_date  \n",
       "0               True        June 6, 2021  \n",
       "1               True       June 14, 2021  \n",
       "2               True  September 12, 2022  \n",
       "3               True     August 10, 2022  \n",
       "4               True        July 5, 2021  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the original dataframe\n",
    "clean_data = raw_reviews.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for Duplicates and NaNs\n",
    "**Let's check for duplicated Amazon.com reviews.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the duplicated reviews\n",
    "clean_data.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About the data\n",
    "\n",
    "- We have a total of 380,639 reviews after removing duplicates.\n",
    "- We have 3,594 duplicated reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate the title and body (keep text column) and clean review date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_date</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-06-06</td>\n",
       "      <td>An Engrossing Page Turner About Race, Class an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-06-14</td>\n",
       "      <td>An Interesting Debut “Hello, Niveus High. It’s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-09-12</td>\n",
       "      <td>Wow I ordered this book for my teenage daughte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-08-10</td>\n",
       "      <td>Definitely a YA novel Great plot, childish cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-07-05</td>\n",
       "      <td>A most timely book. This a very engrossing sto...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  review_date                                            reviews\n",
       "0  2021-06-06  An Engrossing Page Turner About Race, Class an...\n",
       "1  2021-06-14  An Interesting Debut “Hello, Niveus High. It’s...\n",
       "2  2022-09-12  Wow I ordered this book for my teenage daughte...\n",
       "3  2022-08-10  Definitely a YA novel Great plot, childish cha...\n",
       "4  2021-07-05  A most timely book. This a very engrossing sto..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data = clean_data[['title', 'body', 'review_date']]\n",
    "clean_data['reviews'] = clean_data['title'] + \" \" + clean_data['body']\n",
    "clean_data = clean_data.drop(['title', 'body'], axis=1)\n",
    "clean_data['reviews'] = clean_data['reviews'].astype(str)\n",
    "clean_data['review_date'] = clean_data['review_date'].apply(pd.to_datetime)\n",
    "clean_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the reviews\n",
    "clean_data.to_pickle('clean_data_original.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "- There are few cleaning steps that we will perform before moving forward on our reviews:\n",
    "  1. Lower-case the text\n",
    "  2. Remove numbers\n",
    "  3. Remove extra white-spaces(if any)\n",
    "  4. Remove Punctuation\n",
    "  5. Remove Stop-words\n",
    "  6. Lemmatize all words (I prefer lemmatizing instead of stemming - in my final topics, I need coherent words, and not just random words)  \n",
    "  \n",
    "* For stop-words, we will be using an iterative list, which we will begin with an extra long list of stop-words from rank.nl (around 600 words), and then keep on adding domain specific terms as and when we counter through building initial topic models.\n",
    "\n",
    "* We will also create and consider bi-grams and tri-grams in our model to get the best possible set of topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Lower case\n",
    "clean_data['pre_process'] = clean_data['reviews'].apply(lambda x: str(x).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Remove numbers\n",
    "clean_data['pre_process'] = clean_data['pre_process'].apply(lambda x: re.sub(r'\\d+','', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Remove extra spaces\n",
    "clean_data['pre_process'] = clean_data['pre_process'].apply(lambda x: re.sub(' +', ' ', x))\n",
    "clean_data['pre_process'] = clean_data['pre_process'].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Remove punctuation\n",
    "clean_data['pre_process'] = clean_data['pre_process'].apply(lambda x: x.translate(str.maketrans('','',string.punctuation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove contractions\n",
    "def contractions(s):\n",
    "    s = re.sub(r\"won’t\", \"will not\",s)\n",
    "    s = re.sub(r\"would’t\", \"would not\",s)\n",
    "    s = re.sub(r\"could’t\", \"could not\",s)\n",
    "    s = re.sub(r\"\\’d\", \" would\",s)\n",
    "    s = re.sub(r\"can\\’t\", \"can not\",s)\n",
    "    s = re.sub(r\"n\\’t\", \" not\", s)\n",
    "    s = re.sub(r\"\\’re\", \" are\", s)\n",
    "    s = re.sub(r\"\\’s\", \" is\", s)\n",
    "    s = re.sub(r\"\\’ll\", \" will\", s)\n",
    "    s = re.sub(r\"\\’t\", \" not\", s)\n",
    "    s = re.sub(r\"\\’ve\", \" have\", s)\n",
    "    s = re.sub(r\"\\’m\", \" am\", s)\n",
    "    return s\n",
    "\n",
    "clean_data['pre_process'] = clean_data['reviews'].apply(lambda x:contractions(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove any remaining non-alpha characters\n",
    "clean_data['pre_process'] = clean_data['pre_process'].apply(lambda x: \" \".join([re.sub('[^A-Za-z]+','', x) for x in nltk.word_tokenize(x)]))\n",
    "\n",
    "## Lowercase, remove any html tags, remove straggle characters\n",
    "def clean_reviews(text):\n",
    "    '''\n",
    "    Make text lowercase, remove text in square brackets, remove links, remove punctuation\n",
    "    and remove words containing numbers.\n",
    "    '''\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "clean_data['pre_process'] = clean_data['pre_process'].apply(lambda x: clean_reviews(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_date</th>\n",
       "      <th>reviews</th>\n",
       "      <th>pre_process</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-06-06</td>\n",
       "      <td>An Engrossing Page Turner About Race, Class an...</td>\n",
       "      <td>an engrossing page turner about race class and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-06-14</td>\n",
       "      <td>An Interesting Debut “Hello, Niveus High. It’s...</td>\n",
       "      <td>an interesting debut hello niveus high it is m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-09-12</td>\n",
       "      <td>Wow I ordered this book for my teenage daughte...</td>\n",
       "      <td>wow i ordered this book for my teenage daughte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-08-10</td>\n",
       "      <td>Definitely a YA novel Great plot, childish cha...</td>\n",
       "      <td>definitely a ya novel great plot childish char...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-07-05</td>\n",
       "      <td>A most timely book. This a very engrossing sto...</td>\n",
       "      <td>a most timely book this a very engrossing stor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  review_date                                            reviews  \\\n",
       "0  2021-06-06  An Engrossing Page Turner About Race, Class an...   \n",
       "1  2021-06-14  An Interesting Debut “Hello, Niveus High. It’s...   \n",
       "2  2022-09-12  Wow I ordered this book for my teenage daughte...   \n",
       "3  2022-08-10  Definitely a YA novel Great plot, childish cha...   \n",
       "4  2021-07-05  A most timely book. This a very engrossing sto...   \n",
       "\n",
       "                                         pre_process  \n",
       "0  an engrossing page turner about race class and...  \n",
       "1  an interesting debut hello niveus high it is m...  \n",
       "2  wow i ordered this book for my teenage daughte...  \n",
       "3  definitely a ya novel great plot childish char...  \n",
       "4  a most timely book this a very engrossing stor...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Lemmatize reviews\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "clean_data['pre_process'] = clean_data['pre_process'].apply(lambda x: \" \".join([lemmatizer.lemmatize(w) for w in nltk.word_tokenize(x)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_date</th>\n",
       "      <th>reviews</th>\n",
       "      <th>pre_process</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-06-06</td>\n",
       "      <td>An Engrossing Page Turner About Race, Class an...</td>\n",
       "      <td>an engrossing page turner about race class and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-06-14</td>\n",
       "      <td>An Interesting Debut “Hello, Niveus High. It’s...</td>\n",
       "      <td>an interesting debut hello niveus high it is m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-09-12</td>\n",
       "      <td>Wow I ordered this book for my teenage daughte...</td>\n",
       "      <td>wow i ordered this book for my teenage daughte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-08-10</td>\n",
       "      <td>Definitely a YA novel Great plot, childish cha...</td>\n",
       "      <td>definitely a ya novel great plot childish char...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-07-05</td>\n",
       "      <td>A most timely book. This a very engrossing sto...</td>\n",
       "      <td>a most timely book this a very engrossing stor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  review_date                                            reviews  \\\n",
       "0  2021-06-06  An Engrossing Page Turner About Race, Class an...   \n",
       "1  2021-06-14  An Interesting Debut “Hello, Niveus High. It’s...   \n",
       "2  2022-09-12  Wow I ordered this book for my teenage daughte...   \n",
       "3  2022-08-10  Definitely a YA novel Great plot, childish cha...   \n",
       "4  2021-07-05  A most timely book. This a very engrossing sto...   \n",
       "\n",
       "                                         pre_process  \n",
       "0  an engrossing page turner about race class and...  \n",
       "1  an interesting debut hello niveus high it is m...  \n",
       "2  wow i ordered this book for my teenage daughte...  \n",
       "3  definitely a ya novel great plot childish char...  \n",
       "4  a most timely book this a very engrossing stor...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into two dataframes\n",
    "1. Before the first book ban (one year prior - July 1, 2020 to June 30, 2022)\n",
    "2. After the first book ban (July 1, 2021 and after until the dataset ends on October 12, 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_date ='2021-07-01'\n",
    "before_ban_df = clean_data.loc[clean_data['review_date'] < split_date]\n",
    "after_ban_df = clean_data.loc[clean_data['review_date'] >= split_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_date ='2020-07-01'\n",
    "before_ban_df = before_ban_df.loc[before_ban_df['review_date'] >= split_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37492"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(before_ban_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save reviews\n",
    "before_ban_df.to_pickle('before_ban_data.pkl')\n",
    "after_ban_df.to_pickle('after_ban_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2ffc172",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "012fe263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from requests_html import HTMLSession\n",
    "import time\n",
    "from bs4 import BeautifulSoup \n",
    "import re\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88df19eb",
   "metadata": {},
   "source": [
    "## Banned Books List with Amazon Urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c30b423f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Banned Book List with Amazon Links\n",
    "ala_df = pd.read_csv('data/pen_dataset.csv')\n",
    "\n",
    "# Keep certain columns\n",
    "ala_df = ala_df[['Title', 'Author', 'Type of Ban', 'State', 'District','Date of Challenge/Removal', 'Origin of Challenge', 'amazon_url']]\n",
    "\n",
    "# Remove duplicate books for web scraper\n",
    "ala_df = ala_df.drop_duplicates(subset=['Title'])\n",
    "\n",
    "# Remove books without Amazon reviews\n",
    "clean_df = ala_df.dropna(subset=['amazon_url'])\n",
    "\n",
    "# Add the unique Amazon book review urls to a list to feed into the web scraper\n",
    "urls = list(clean_df['amazon_url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b14fb1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique books is 1547\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of unique books is\", len(urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112dab3d",
   "metadata": {},
   "source": [
    "## Scrape Amazon Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "845e17ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reviews:\n",
    "    \n",
    "    review_date_pattern = re.compile('(?:Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|Apr(?:il)?|May|Jun(?:e)?|Jul(?:y)?|Aug(?:ust)?|Sep(?:tember)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember)?) \\d+, \\d{4}')\n",
    "    product_name_pattern = re.compile('^https:\\/{2}www.amazon.com\\/(.+)\\/product-reviews')\n",
    "    \n",
    "    def __init__(self, url) -> None:\n",
    "        \"\"\"Initialize a session.\"\"\"\n",
    "        \n",
    "        self.session = HTMLSession()\n",
    "        self.headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.5112.81 Safari/537.36'}\n",
    "        self.session.headers['Accept'] = 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8'\n",
    "        self.session.headers['Accept-Language'] = 'en-US,en;q=0.5'\n",
    "        self.session.headers['Connection'] = 'keep-alive'\n",
    "        self.session.headers['Upgrade-Insecure-Requests'] = '1'        \n",
    "        self.url = url\n",
    "        \n",
    "    def pagination(self, page):\n",
    "        \"\"\"Work through pagination.\"\"\"\n",
    "        \n",
    "        r = self.session.get(self.url + str(page))\n",
    "        print(self.url + str(page))\n",
    "\n",
    "        if not r.html.find('div[data-hook=review]'):\n",
    "            return False\n",
    "\n",
    "        else:\n",
    "            return r.html.find('div[data-hook=review]')\n",
    "\n",
    "    def parse(self, reviews, page):\n",
    "        \"\"\"Parse the html.\"\"\"\n",
    "        \n",
    "        total = []\n",
    "        \n",
    "        response = self.session.get(self.url + str(page))\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        review_list = soup.find('div', {'id': 'cm_cr-review_list' })  \n",
    "        product_reviews = review_list.find_all('div', {'data-hook': 'review'}) \n",
    "        product_name = self.product_name_pattern.search(self.url).group(1) if self.product_name_pattern.search(self.url) else ''\n",
    "\n",
    "        if not product_name:\n",
    "            print('url is invalid. Please check the url.')\n",
    "            product_name = self.url\n",
    "            return\n",
    "        else:\n",
    "            product_name = product_name.replace('-', ' ')\n",
    "        \n",
    "        for review in product_reviews:\n",
    "            \n",
    "            try:\n",
    "                title = review.find('a', {'data-hook': 'review-title'}).text.strip()\n",
    "            except:\n",
    "                print('No title')\n",
    "                break\n",
    "             \n",
    "            try:\n",
    "                body = review.find('span', {'data-hook': 'review-body'}).text.strip()\n",
    "            except: \n",
    "                print('No body')\n",
    "                break\n",
    "                \n",
    "            try:\n",
    "                rating = review.find('i', {'data-hook': 'review-star-rating'}).text\n",
    "            except:\n",
    "                print('No rating')\n",
    "                break\n",
    "                \n",
    "            try:\n",
    "                verified_purchase = True if review.find('span', {'data-hook': 'avp-badge'}) else False\n",
    "            except: \n",
    "                print('No verified purchase')\n",
    "                break\n",
    "\n",
    "            try:\n",
    "                review_date = self.review_date_pattern.search(review.find('span', {'data-hook': 'review-date'}).text).group(0)\n",
    "            except:\n",
    "                print('No review date')\n",
    "                break\n",
    "                \n",
    "            data = {\n",
    "                'product_name': product_name,\n",
    "                'title': title,\n",
    "                'body': body,\n",
    "                'rating': rating,\n",
    "                'verified_purchase': verified_purchase,\n",
    "                'review_date': review_date\n",
    "            }\n",
    "\n",
    "            total.append(data)\n",
    "\n",
    "        \n",
    "        return total\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4479c957",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                             | 0/1547 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting page  1\n",
      "https://www.amazon.com/Ace-Spades-Faridah-Abike-Iyimide/product-reviews/1250800811/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviewssortBy=recent&pageNumber=1\n",
      "getting page  2\n",
      "https://www.amazon.com/Ace-Spades-Faridah-Abike-Iyimide/product-reviews/1250800811/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviewssortBy=recent&pageNumber=2\n",
      "getting page  3\n",
      "https://www.amazon.com/Ace-Spades-Faridah-Abike-Iyimide/product-reviews/1250800811/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviewssortBy=recent&pageNumber=3\n",
      "getting page  4\n",
      "https://www.amazon.com/Ace-Spades-Faridah-Abike-Iyimide/product-reviews/1250800811/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviewssortBy=recent&pageNumber=4\n",
      "getting page  5\n",
      "https://www.amazon.com/Ace-Spades-Faridah-Abike-Iyimide/product-reviews/1250800811/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviewssortBy=recent&pageNumber=5\n",
      "getting page  6\n",
      "https://www.amazon.com/Ace-Spades-Faridah-Abike-Iyimide/product-reviews/1250800811/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviewssortBy=recent&pageNumber=6\n",
      "getting page  7\n",
      "https://www.amazon.com/Ace-Spades-Faridah-Abike-Iyimide/product-reviews/1250800811/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviewssortBy=recent&pageNumber=7\n",
      "getting page  8\n",
      "https://www.amazon.com/Ace-Spades-Faridah-Abike-Iyimide/product-reviews/1250800811/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviewssortBy=recent&pageNumber=8\n",
      "getting page  9\n",
      "https://www.amazon.com/Ace-Spades-Faridah-Abike-Iyimide/product-reviews/1250800811/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviewssortBy=recent&pageNumber=9\n",
      "getting page  10\n",
      "https://www.amazon.com/Ace-Spades-Faridah-Abike-Iyimide/product-reviews/1250800811/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviewssortBy=recent&pageNumber=10\n",
      "getting page  11\n",
      "https://www.amazon.com/Ace-Spades-Faridah-Abike-Iyimide/product-reviews/1250800811/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviewssortBy=recent&pageNumber=11\n",
      "getting page  12\n",
      "https://www.amazon.com/Ace-Spades-Faridah-Abike-Iyimide/product-reviews/1250800811/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviewssortBy=recent&pageNumber=12\n",
      "getting page  13\n",
      "https://www.amazon.com/Ace-Spades-Faridah-Abike-Iyimide/product-reviews/1250800811/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviewssortBy=recent&pageNumber=13\n",
      "getting page  14\n",
      "https://www.amazon.com/Ace-Spades-Faridah-Abike-Iyimide/product-reviews/1250800811/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviewssortBy=recent&pageNumber=14\n",
      "getting page  15\n",
      "https://www.amazon.com/Ace-Spades-Faridah-Abike-Iyimide/product-reviews/1250800811/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviewssortBy=recent&pageNumber=15\n",
      "getting page  16\n",
      "https://www.amazon.com/Ace-Spades-Faridah-Abike-Iyimide/product-reviews/1250800811/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviewssortBy=recent&pageNumber=16\n",
      "getting page  17\n",
      "https://www.amazon.com/Ace-Spades-Faridah-Abike-Iyimide/product-reviews/1250800811/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviewssortBy=recent&pageNumber=17\n",
      "getting page  18\n",
      "https://www.amazon.com/Ace-Spades-Faridah-Abike-Iyimide/product-reviews/1250800811/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviewssortBy=recent&pageNumber=18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                             | 0/1547 [00:25<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting page  19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1000\u001b[39m):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgetting page \u001b[39m\u001b[38;5;124m'\u001b[39m, x)\n\u001b[0;32m---> 16\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     reviews \u001b[38;5;241m=\u001b[39m amz\u001b[38;5;241m.\u001b[39mpagination(x)\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m reviews \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    dfs = [] \n",
    "    \n",
    "    for url in tqdm(urls):\n",
    "        \n",
    "        full_url = url + 'sortBy=recent&pageNumber='\n",
    "    \n",
    "        amz=Reviews(full_url)\n",
    "\n",
    "        results = []\n",
    "\n",
    "        for x in range(1,1000):\n",
    "\n",
    "            print('getting page ', x)\n",
    "            time.sleep(0.4)\n",
    "\n",
    "            reviews = amz.pagination(x)\n",
    "\n",
    "            if reviews is not False:\n",
    "                results.append(amz.parse(reviews, x))\n",
    "\n",
    "            else:\n",
    "                print('No more review pages.')\n",
    "                break\n",
    "\n",
    "        flat_list = [item for sublist in results for item in sublist]\n",
    "\n",
    "        df = pd.DataFrame(flat_list)\n",
    "        dfs.append(df)\n",
    "        \n",
    "    pd.concat(dfs).to_csv(r'out_amz_full.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
